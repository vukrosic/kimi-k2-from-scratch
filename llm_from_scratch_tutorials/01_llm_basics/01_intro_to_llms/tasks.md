# Tasks: Introduction to LLMs

## Task 1: Define LLM in Your Words (5 min)
Write 1-2 paragraphs explaining what an LLM is, based on the lecture. Include: Core task, why probabilities, one example.

Example Starter: "An LLM is an AI that..."

## Task 2: List Famous LLMs (3 min)
Research 3 more LLMs (beyond GPT, Llama, DeepSeek). Note company and key feature (e.g., open-source?).

## Task 3: Why Scratch? (10 min)
Brainstorm 3 personal reasons to build an LLM from scratch. E.g., "To understand attention mechanism."

## Task 4: Run Code Snippet (5 min)
Run `code_snippets.py`. Modify probs/vocab, observe greedy vs. random. Note: How does changing probs affect outputs?

## Submission
- Write answers in a notebook or text file.
- Share on forum/GitHub for feedback.

## Solutions/Hints
- Task 1: Focus on next-token prediction.
- Task 4: Higher prob â†’ More likely in random.

Next: Micro-Lecture 1.2 Tasks.
