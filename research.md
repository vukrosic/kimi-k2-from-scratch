Moonshot AI’s Kimi K2 – Open Agentic Intelligence
Moonshot AI’s Kimi K2 is a state-of-the-art open-source language model built on a Mixture‑of‑Experts (MoE) architecture. It has 1 trillion total parameters with 32 billion activated parameters per inference[1][2]. Kimi K2 was trained using Moonshot’s novel MuonClip optimizer, which allowed stable pretraining on 15.5 trillion tokens with no loss spikes[3]. The model is explicitly optimized for “agentic” tasks – i.e. reasoning, tool use, and autonomous problem solving – and excels at coding, math, and knowledge benchmarks[1][4]. Moonshot reports that Kimi K2 achieves state-of-the-art open‑source performance on a variety of tests (e.g. Tau2-Bench, ACEBench, SWE-Bench, LiveCodeBench, AIME, GPQA, OJBench, etc.)[4][1]. Moonshot has released both the base model and a post‑trained Instruct model (fine‑tuned for chat/agentic use) as checkpoints for public use[5][6].
Key Features: Kimi K2 is a 1T‑parameter MoE model pre-trained on 15.5T tokens with zero training instability[7][3]. Its training used an unprecedented scale of Moonshot’s Muon/MuonClip optimizer with new techniques (QK‑clip) to stabilize learning[3][7]. It was designed specifically for agentic intelligence, incorporating multi-stage post-training (large-scale synthetic agentic data, reinforcement learning with tool use)[8]. The model originally supports a long 128K-token context window, tailored for “deep thinking” and long-form tasks, and its architecture features 384 experts (8 active) and 64 attention heads per layer[7][9].
Variants: Moonshot provides two versions of Kimi K2[6]:
Kimi-K2-Base: The raw foundation model (1T MoE) for researchers to fine-tune and build custom solutions[6].
Kimi-K2-Instruct: A post-trained variant optimized for dialog and agentic scenarios. It is described as a “reflex-grade” model for general-purpose chat/agent use (no extra “long thinking”)[6]. Both variants’ weights are published by Moonshot on HuggingFace and ModelScope for open use[10][5].
Performance and Benchmarks
Moonshot’s technical report highlights Kimi K2’s top-tier performance. In non-thinking (no chain-of-thought) settings, K2 achieves 66.1 on Tau2-Bench, 76.5 on ACEBench (English), 65.8 on SWE-Bench Verified, and 47.3 on SWE-Bench Multilingual[4] – often surpassing other open- and closed-source models. It also excels in code and math: 53.7 on LiveCodeBench v6, 27.1 on OJBench, 49.5 on AIME 2025, 75.1 on GPQA-Diamond, etc. (all w/o extended reasoning)[4]. These results “position Kimi K2 as one of the most capable open-source LLMs to date, particularly in software engineering and agentic tasks”[4][5]. Moonshot notes that K2’s strengths lie especially in coding, math, and agentic problem-solving.
Recent Updates (0905 Version)
In a September 5, 2025 blog post, Moonshot announced an updated Kimi K2 model (v0905) with enhanced capabilities[11]. The key improvements include: - Extended context window: The context length was doubled from 128K to 256K tokens for handling very long, complex tasks[12]. - High-speed API: A new “turbo” inference mode supports 60–100 tokens/sec output, enabling much faster response rates[13]. - Improved agentic coding: Enhanced performance on realistic coding tasks and benchmarks (front-end code quality and practicality were specifically noted as improved)[14]. - Tool-call enhancements: Features like guaranteed JSON/tool-call formatting and automatic context caching were added to improve developer experience (per Moonshot’s blog)[15].
The blog confirms Kimi K2 was first released on July 11, 2025, as an open-source MoE model with 1T total and 32B active parameters[16]. It notes that many coding tools (Cursor, Windsurf, Trae, Cline, RooCode, Kilo Code, etc.) have integrated K2, and cloud providers worldwide offer K2 instances for developers[16]. The K2 v0905 model and a high-speed “turbo” version are available via Moonshot’s API platform, and the updated weights can be downloaded from HuggingFace or ModelScope[10][11].
Official Resources and Links
Moonshot AI provides all Kimi K2 materials openly. In their “Kimi K2 Folder,” Moonshot links to the official Kimi K2 Tech Blog, Technical Report, and GitHub repo[17]. These include: - Tech Blog (GitHub Pages): “Kimi K2: Open Agentic Intelligence” page with an overview and features. - Technical Report (arXiv): “Kimi K2: Open Agentic Intelligence” by the Kimi Team[2][4], detailing architecture, training (MuonClip), and evaluation results. - GitHub Repository: MoonshotAI/Kimi-K2 with README, figures, and checkpoints (including links to base and instruct weights)[17][5].
These official sources (in English and Chinese) contain the complete documentation, announcements, and data for Kimi K2. Moonshot’s Chinese blog provides key announcements (including the v0905 update)[11][16], while the GitHub and arXiv entries give full technical details and results[1][4]. Collectively, they represent all information Moonshot AI has published about Kimi K2 to date.
Sources: Official Moonshot AI publications (tech blog, GitHub repo, and arXiv report) and the company’s platform announcements[1][4][11][16].

[1] [6] [7] [9] GitHub - MoonshotAI/Kimi-K2: Kimi K2 is the large language model series developed by Moonshot AI team
https://github.com/MoonshotAI/Kimi-K2
[2] [3] [4] [5] [8] Kimi K2: Open Agentic Intelligence
https://arxiv.org/pdf/2507.20534
[10] [11] [12] [13] [14] [15] [16] [17] Kimi K2 模型更新，带来更强的代码能力、更快的 API
https://platform.moonshot.cn/blog/posts/kimi-k2-0905